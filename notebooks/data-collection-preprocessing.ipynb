{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "S&P500 ETF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to 'sp500_daily_prices.csv'\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Replace with your Alpha Vantage API key\n",
    "API_KEY = 'Z358OL15QMSRKU2R'\n",
    "\n",
    "def fetch_sp500_data(api_key, start_date, end_date):\n",
    "    symbol = 'SPY'  # ETF tracking the S&P 500 index\n",
    "    function = 'TIME_SERIES_DAILY'\n",
    "    url = f'https://www.alphavantage.co/query?function={function}&symbol={symbol}&apikey={api_key}&outputsize=full'\n",
    "\n",
    "    response = requests.get(url)\n",
    "    data = response.json()\n",
    "\n",
    "    if 'Time Series (Daily)' in data:\n",
    "        df = pd.DataFrame.from_dict(data['Time Series (Daily)'], orient='index', dtype=float)\n",
    "        df.index = pd.to_datetime(df.index)\n",
    "        df = df.rename(columns=lambda x: x[3:])  # Remove the '1. ', '2. ', etc. prefixes\n",
    "        df = df[(df.index >= start_date) & (df.index <= end_date)]\n",
    "        df.sort_index(inplace=True)\n",
    "        return df\n",
    "    else:\n",
    "        print(\"Error fetching data:\", data.get(\"Error Message\", \"Unknown error\"))\n",
    "        return None\n",
    "\n",
    "# Define date range\n",
    "start_date = datetime(2012, 11, 27)\n",
    "end_date = datetime.today()\n",
    "\n",
    "# Fetch data\n",
    "sp500_data = fetch_sp500_data(API_KEY, start_date, end_date)\n",
    "\n",
    "if sp500_data is not None:\n",
    "    # Save to CSV\n",
    "    sp500_data.to_csv('sp500_daily_prices.csv')\n",
    "    print(\"Data saved to 'sp500_daily_prices.csv'\")\n",
    "else:\n",
    "    print(\"Failed to retrieve data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Investment Sectors Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting yfinance\n",
      "  Downloading yfinance-0.2.50-py2.py3-none-any.whl.metadata (5.5 kB)\n",
      "Requirement already satisfied: pandas>=1.3.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from yfinance) (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.16.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from yfinance) (2.1.3)\n",
      "Requirement already satisfied: requests>=2.31 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from yfinance) (2.32.3)\n",
      "Collecting multitasking>=0.0.7 (from yfinance)\n",
      "  Downloading multitasking-0.0.11-py3-none-any.whl.metadata (5.5 kB)\n",
      "Collecting lxml>=4.9.1 (from yfinance)\n",
      "  Downloading lxml-5.3.0-cp312-cp312-macosx_10_9_universal2.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: platformdirs>=2.0.0 in /Users/altemir_1/Library/Python/3.12/lib/python/site-packages (from yfinance) (4.3.6)\n",
      "Requirement already satisfied: pytz>=2022.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from yfinance) (2024.2)\n",
      "Collecting frozendict>=2.3.4 (from yfinance)\n",
      "  Downloading frozendict-2.4.6-py312-none-any.whl.metadata (23 kB)\n",
      "Collecting peewee>=3.16.2 (from yfinance)\n",
      "  Downloading peewee-3.17.8.tar.gz (948 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m948.2/948.2 kB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting beautifulsoup4>=4.11.1 (from yfinance)\n",
      "  Using cached beautifulsoup4-4.12.3-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting html5lib>=1.1 (from yfinance)\n",
      "  Downloading html5lib-1.1-py2.py3-none-any.whl.metadata (16 kB)\n",
      "Collecting soupsieve>1.2 (from beautifulsoup4>=4.11.1->yfinance)\n",
      "  Using cached soupsieve-2.6-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: six>=1.9 in /Users/altemir_1/Library/Python/3.12/lib/python/site-packages (from html5lib>=1.1->yfinance) (1.16.0)\n",
      "Collecting webencodings (from html5lib>=1.1->yfinance)\n",
      "  Downloading webencodings-0.5.1-py2.py3-none-any.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/altemir_1/Library/Python/3.12/lib/python/site-packages (from pandas>=1.3.0->yfinance) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas>=1.3.0->yfinance) (2024.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests>=2.31->yfinance) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests>=2.31->yfinance) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests>=2.31->yfinance) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests>=2.31->yfinance) (2024.8.30)\n",
      "Downloading yfinance-0.2.50-py2.py3-none-any.whl (102 kB)\n",
      "Using cached beautifulsoup4-4.12.3-py3-none-any.whl (147 kB)\n",
      "Downloading frozendict-2.4.6-py312-none-any.whl (16 kB)\n",
      "Downloading html5lib-1.1-py2.py3-none-any.whl (112 kB)\n",
      "Downloading lxml-5.3.0-cp312-cp312-macosx_10_9_universal2.whl (8.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.2/8.2 MB\u001b[0m \u001b[31m41.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading multitasking-0.0.11-py3-none-any.whl (8.5 kB)\n",
      "Using cached soupsieve-2.6-py3-none-any.whl (36 kB)\n",
      "Downloading webencodings-0.5.1-py2.py3-none-any.whl (11 kB)\n",
      "Building wheels for collected packages: peewee\n",
      "  Building wheel for peewee (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for peewee: filename=peewee-3.17.8-cp312-cp312-macosx_10_13_universal2.whl size=419633 sha256=fb50010c68d8a054dbd5b3125acad0e5044b7f8c4132a91673885c69e4c156b2\n",
      "  Stored in directory: /Users/altemir_1/Library/Caches/pip/wheels/8f/65/34/456800445efeafb05164fe95285c70e81ba1d96bae30f43917\n",
      "Successfully built peewee\n",
      "Installing collected packages: webencodings, peewee, multitasking, soupsieve, lxml, html5lib, frozendict, beautifulsoup4, yfinance\n",
      "Successfully installed beautifulsoup4-4.12.3 frozendict-2.4.6 html5lib-1.1 lxml-5.3.0 multitasking-0.0.11 peewee-3.17.8 soupsieve-2.6 webencodings-0.5.1 yfinance-0.2.50\n"
     ]
    }
   ],
   "source": [
    "!pip install yfinance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data for Technology (XLK)...\n",
      "Data for Technology saved to 'Technology_daily_prices.csv'.\n",
      "Fetching data for Energy (XLE)...\n",
      "Data for Energy saved to 'Energy_daily_prices.csv'.\n",
      "Fetching data for Health Care (XLV)...\n",
      "Data for Health Care saved to 'Health Care_daily_prices.csv'.\n",
      "Fetching data for Financials (XLF)...\n",
      "Data for Financials saved to 'Financials_daily_prices.csv'.\n",
      "Fetching data for Consumer Discretionary (XLY)...\n",
      "Data for Consumer Discretionary saved to 'Consumer Discretionary_daily_prices.csv'.\n",
      "Fetching data for Consumer Staples (XLP)...\n",
      "Data for Consumer Staples saved to 'Consumer Staples_daily_prices.csv'.\n",
      "Fetching data for Utilities (XLU)...\n",
      "Data for Utilities saved to 'Utilities_daily_prices.csv'.\n",
      "Fetching data for Industrials (XLI)...\n",
      "Data for Industrials saved to 'Industrials_daily_prices.csv'.\n",
      "Fetching data for Materials (XLB)...\n",
      "Data for Materials saved to 'Materials_daily_prices.csv'.\n",
      "Fetching data for Real Estate (XLRE)...\n",
      "Data for Real Estate saved to 'Real Estate_daily_prices.csv'.\n",
      "Fetching data for Communication Services (XLC)...\n",
      "Data for Communication Services saved to 'Communication Services_daily_prices.csv'.\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Sector Tickers\n",
    "sector_tickers = {\n",
    "    \"Technology\": \"XLK\",\n",
    "    \"Energy\": \"XLE\",\n",
    "    \"Health Care\": \"XLV\",\n",
    "    \"Financials\": \"XLF\",\n",
    "    \"Consumer Discretionary\": \"XLY\",\n",
    "    \"Consumer Staples\": \"XLP\",\n",
    "    \"Utilities\": \"XLU\",\n",
    "    \"Industrials\": \"XLI\",\n",
    "    \"Materials\": \"XLB\",\n",
    "    \"Real Estate\": \"XLRE\",\n",
    "    \"Communication Services\": \"XLC\"\n",
    "}\n",
    "\n",
    "# Define date range\n",
    "start_date = \"2012-11-27\"\n",
    "end_date = datetime.today().strftime('%Y-%m-%d')\n",
    "\n",
    "# Fetch and save data for each sector\n",
    "all_sector_data = {}\n",
    "\n",
    "for sector, ticker in sector_tickers.items():\n",
    "    print(f\"Fetching data for {sector} ({ticker})...\")\n",
    "    try:\n",
    "        # Download data using yfinance\n",
    "        df = yf.download(ticker, start=start_date, end=end_date, progress=False)\n",
    "        df.reset_index(inplace=True)  # Reset index to include dates as a column\n",
    "        df.to_csv(f\"/Users/altemir_1/Desktop/BTC-Stock-Market-Analysis/data/raw/{sector}_daily_prices.csv\", index=False)  # Save to CSV\n",
    "        print(f\"Data for {sector} saved to '{sector}_daily_prices.csv'.\")\n",
    "        all_sector_data[sector] = df\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to fetch data for {sector}: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vx/qnjn5crx6n17qty1n6m8kf4w0000gn/T/ipykernel_3147/2722473491.py:5: DtypeWarning: Columns (3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  sectors = pd.read_csv(\"/Users/altemir_1/Desktop/BTC-Stock-Market-Analysis/data/raw/investment_sectors_historical_data.csv\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "btc = pd.read_csv(\"/Users/altemir_1/Desktop/BTC-Stock-Market-Analysis/data/raw/bitcoin_historical_data.csv\")\n",
    "sp500 = pd.read_csv(\"/Users/altemir_1/Desktop/BTC-Stock-Market-Analysis/data/raw/sp500_historical_data.csv\")\n",
    "sectors = pd.read_csv(\"/Users/altemir_1/Desktop/BTC-Stock-Market-Analysis/data/raw/investment_sectors_historical_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Date        0\n",
      "Price       0\n",
      "Open        0\n",
      "High        0\n",
      "Low         0\n",
      "Vol.        0\n",
      "Change %    0\n",
      "dtype: int64\n",
      "----------------------------------------\n",
      "Unnamed: 0    0\n",
      "open          0\n",
      "high          0\n",
      "low           0\n",
      "close         0\n",
      "volume        0\n",
      "dtype: int64\n",
      "----------------------------------------\n",
      "Price             0\n",
      "Unnamed: 1        1\n",
      "Date              1\n",
      "Adj Close     28170\n",
      "Close         28170\n",
      "              ...  \n",
      "Close.10      29569\n",
      "High.10       29569\n",
      "Low.10        29569\n",
      "Open.10       29569\n",
      "Volume.10     29569\n",
      "Length: 69, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def check_for_null_values(df):\n",
    "    print(\"-\" * 40)\n",
    "    return df.isnull().sum()\n",
    "\n",
    "data = [btc, sp500, sectors]\n",
    "\n",
    "for df in data:\n",
    "    print(check_for_null_values(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bitcoin and S&P 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping and renaming columns in btc and sp500 dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "def drop_unnecessary_columns(df, columns):\n",
    "   return df.drop(columns=columns)\n",
    "\n",
    "def rename_columns(df, columns):\n",
    "   return df.rename(columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating list and dict of columns to drop and rename\n",
    "btc_columns_to_drop = [\"Open\", \"High\", \"Low\"]\n",
    "sp500_columns_to_drop = [\"open\", \"high\", \"low\"]\n",
    "\n",
    "btc_rename_columns = {\"Date\":\"date\", \"Price\": \"price\", \"Vol.\": \"volume\", \"Change %\": \"change_rate\"}\n",
    "sp500_rename_columns = {\"close\": \"price\", \"Unnamed: 0\": \"date\"}\n",
    "\n",
    "# Applying helper functions\n",
    "btc = drop_unnecessary_columns(btc, btc_columns_to_drop)\n",
    "btc = rename_columns(btc, btc_rename_columns)\n",
    "\n",
    "sp500 = drop_unnecessary_columns(sp500, sp500_columns_to_drop)\n",
    "sp500 = rename_columns(sp500, sp500_rename_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting date in both dfs to one format of date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    2024-12-10\n",
      "1    2024-12-09\n",
      "2    2024-12-08\n",
      "3    2024-12-07\n",
      "4    2024-12-06\n",
      "Name: date, dtype: object\n",
      "0    2012-11-27\n",
      "1    2012-11-28\n",
      "2    2012-11-29\n",
      "3    2012-11-30\n",
      "4    2012-12-03\n",
      "Name: date, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Convert date columns in both DataFrames to datetime\n",
    "btc['date'] = pd.to_datetime(btc['date'])\n",
    "sp500['date'] = pd.to_datetime(sp500['date'])\n",
    "\n",
    "# Optionally, format as string in 'YYYY-MM-DD' format\n",
    "btc['date'] = btc['date'].dt.strftime('%Y-%m-%d')\n",
    "sp500['date'] = sp500['date'].dt.strftime('%Y-%m-%d')\n",
    "\n",
    "# Verify the format\n",
    "print(btc['date'].head())\n",
    "print(sp500['date'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding change_rate to sp500 df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate daily percentage change for S&P 500\n",
    "sp500['change_rate'] = sp500['price'].pct_change() * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting object columns that contain numerical data to the numerical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updated function to convert volume from BTC to USD\n",
    "def convert_volume_to_usd(volume, price):\n",
    "    \"\"\"\n",
    "    Convert volume from BTC to USD by handling shorthand notation\n",
    "    (K for thousand, M for million, B for billion) and then multiplying\n",
    "    by the Bitcoin price on the respective date.\n",
    "    \"\"\"\n",
    "    if \"K\" in volume:\n",
    "        volume_value = float(volume.replace(\"K\", \"\")) * 1_000\n",
    "    elif \"M\" in volume:\n",
    "        volume_value = float(volume.replace(\"M\", \"\")) * 1_000_000\n",
    "    elif \"B\" in volume:\n",
    "        volume_value = float(volume.replace(\"B\", \"\")) * 1_000_000_000\n",
    "    else:\n",
    "        volume_value = float(volume)  # Handle cases without suffix\n",
    "\n",
    "    # Convert to USD by multiplying by the price on the same date\n",
    "    return volume_value * price\n",
    "\n",
    "\n",
    "# Convert price to float\n",
    "# Ensure the column is of string type\n",
    "btc[\"price\"] = btc[\"price\"].astype(str)\n",
    "\n",
    "# Replace commas and convert to float\n",
    "btc[\"price\"] = btc[\"price\"].str.replace(\",\", \"\").astype(float)\n",
    "\n",
    "\n",
    "btc[\"volume\"] = btc[\"volume\"].astype(str)\n",
    "# Apply the updated function to the DataFrame\n",
    "btc[\"volume\"] = btc.apply(lambda row: convert_volume_to_usd(row[\"volume\"], row[\"price\"]), axis=1)\n",
    "\n",
    "# Convert change_rate to float (removing '%' and dividing by 100 if needed)\n",
    "btc[\"change_rate\"] = btc[\"change_rate\"].str.replace(\"%\", \"\").astype(float)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Investment Sectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading each sector into dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Define the folder path where all sector CSVs are stored\n",
    "folder_path = \"/Users/altemir_1/Desktop/BTC-Stock-Market-Analysis/data/raw/investment_sectors/\"  # Replace with the actual folder path\n",
    "\n",
    "# Create a dictionary to store DataFrames for each sector\n",
    "sector_dfs = {}\n",
    "\n",
    "# Iterate through the folder to load all CSV files into DataFrames\n",
    "for file_name in os.listdir(folder_path):\n",
    "    if file_name.endswith(\".csv\"):  # Ensure it's a CSV file\n",
    "        sector_name = file_name.replace(\"_daily_prices.csv\", \"\").replace(\"_\", \" \")\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        sector_dfs[sector_name] = pd.read_csv(file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defininng functions to preprocess dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_columns(df):\n",
    "    columns = [\"Adj Close\", \"High\", \"Low\", \"Open\"]\n",
    "    df.drop(columns=columns, inplace=True)\n",
    "\n",
    "# First row contains NaN values and Tickers \n",
    "def drop_first_row(df):\n",
    "    return df.iloc[1:].reset_index(drop=True)\n",
    "\n",
    "def rename_columns(df):\n",
    "    columns = {\"Date\": \"date\", \"Close\": \"price\", \"Volume\": \"volume\"}\n",
    "    return df.rename(columns=columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sector, df in sector_dfs.items():\n",
    "    try:\n",
    "        sector_dfs[sector] = drop_columns(df)\n",
    "    except KeyError:\n",
    "        print(\"Columns already deleted\")\n",
    "    sector_dfs[sector] = drop_first_row(df)\n",
    "\n",
    "    sector_dfs[sector] = rename_columns(df)\n",
    "\n",
    "\n",
    "    # Convert 'Date' column to datetime\n",
    "    sector_dfs[sector][\"date\"] = pd.to_datetime(sector_dfs[sector][\"date\"], format=\"%Y-%m-%d\", errors=\"coerce\")  # Automatically detects multiple formats\n",
    "\n",
    "    # Ensure all dates are in the same format\n",
    "    sector_dfs[sector][\"date\"] = sector_dfs[sector][\"date\"].dt.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    # Convert object values into numerical\n",
    "    sector_dfs[sector][\"volume\"] = sector_dfs[sector][\"volume\"].astype(float)\n",
    "    sector_dfs[sector][\"price\"] = sector_dfs[sector][\"price\"].astype(float)\n",
    "\n",
    "    # Adding percent of return\n",
    "    sector_dfs[sector][\"change_rate\"] = sector_dfs[sector]['price'].pct_change() * 100\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merging all sectors into one csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_sector_dfs(sector_dfs):\n",
    "    # Add a new column to each DataFrame to identify its sector\n",
    "    for sector, df in sector_dfs.items():\n",
    "        df['sector'] = sector  # Add the sector name as a new column\n",
    "\n",
    "    # Concatenate all DataFrames vertically\n",
    "    merged_df = pd.concat(sector_dfs.values(), axis=0, ignore_index=True)\n",
    "\n",
    "    return merged_df\n",
    "\n",
    "all_sectors_df  = merge_sector_dfs(sector_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>volume</th>\n",
       "      <th>sector</th>\n",
       "      <th>change_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2012-11-27</td>\n",
       "      <td>34.610001</td>\n",
       "      <td>13662900.0</td>\n",
       "      <td>utilities</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2012-11-28</td>\n",
       "      <td>34.750000</td>\n",
       "      <td>10529100.0</td>\n",
       "      <td>utilities</td>\n",
       "      <td>0.404506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2012-11-29</td>\n",
       "      <td>34.950001</td>\n",
       "      <td>9565800.0</td>\n",
       "      <td>utilities</td>\n",
       "      <td>0.575542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2012-11-30</td>\n",
       "      <td>35.320000</td>\n",
       "      <td>29063200.0</td>\n",
       "      <td>utilities</td>\n",
       "      <td>1.058652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2012-12-03</td>\n",
       "      <td>35.099998</td>\n",
       "      <td>12502700.0</td>\n",
       "      <td>utilities</td>\n",
       "      <td>-0.622880</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index        date      price      volume     sector  change_rate\n",
       "0      1  2012-11-27  34.610001  13662900.0  utilities          NaN\n",
       "1      2  2012-11-28  34.750000  10529100.0  utilities     0.404506\n",
       "2      3  2012-11-29  34.950001   9565800.0  utilities     0.575542\n",
       "3      4  2012-11-30  35.320000  29063200.0  utilities     1.058652\n",
       "4      5  2012-12-03  35.099998  12502700.0  utilities    -0.622880"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_sectors_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp500 = sp500.fillna(0)\n",
    "all_sectors_df = all_sectors_df.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processed Data Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BTC DataFrame saved to /Users/altemir_1/Desktop/BTC-Stock-Market-Analysis/data/processed/btc_processed.csv\n",
      "S&P 500 DataFrame saved to /Users/altemir_1/Desktop/BTC-Stock-Market-Analysis/data/processed/sp500_processed.csv\n",
      "All Sectors DataFrame saved to /Users/altemir_1/Desktop/BTC-Stock-Market-Analysis/data/processed/all_sectors_processed.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Base folder path where the CSVs will be saved\n",
    "base_folder_path = \"/Users/altemir_1/Desktop/BTC-Stock-Market-Analysis/data/processed/\"\n",
    "\n",
    "# Ensure the folder exists\n",
    "os.makedirs(base_folder_path, exist_ok=True)\n",
    "\n",
    "# Save the BTC DataFrame\n",
    "btc_csv_path = os.path.join(base_folder_path, \"btc_processed.csv\")\n",
    "btc.to_csv(btc_csv_path, index=False)\n",
    "print(f\"BTC DataFrame saved to {btc_csv_path}\")\n",
    "\n",
    "# Save the SP500 DataFrame\n",
    "sp500_csv_path = os.path.join(base_folder_path, \"sp500_processed.csv\")\n",
    "sp500.to_csv(sp500_csv_path, index=False)\n",
    "print(f\"S&P 500 DataFrame saved to {sp500_csv_path}\")\n",
    "\n",
    "# Save the merged all_sectors_df\n",
    "all_sectors_csv_path = os.path.join(base_folder_path, \"all_sectors_processed.csv\")\n",
    "all_sectors_df.to_csv(all_sectors_csv_path, index=False)\n",
    "print(f\"All Sectors DataFrame saved to {all_sectors_csv_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
